{
  "name": "MultiAgentSwarm",
  "models": {
    "agent_swarm": {
      "batch_size": 2,
      "grid_rows": 1,
      "grid_cols": 2,
      "layers_per_cell": 1,
      "layers": [
        {
          "type": "dense",
          "input_size": 20,
          "output_size": 32,
          "activation": "relu",
          "comment": "Shared perception layer"
        },
        {
          "type": "parallel",
          "combine_mode": "grid_scatter",
          "grid_output_rows": 2,
          "grid_output_cols": 2,
          "grid_output_layers": 1,
          "grid_positions": [
            {
              "branch_index": 0,
              "target_row": 0,
              "target_col": 0,
              "target_layer": 0
            },
            {
              "branch_index": 1,
              "target_row": 0,
              "target_col": 1,
              "target_layer": 0
            },
            {
              "branch_index": 2,
              "target_row": 1,
              "target_col": 0,
              "target_layer": 0
            },
            {
              "branch_index": 3,
              "target_row": 1,
              "target_col": 1,
              "target_layer": 0
            }
          ],
          "branches": [
            {
              "type": "lstm",
              "input_size": 32,
              "hidden_size": 10,
              "seq_length": 1,
              "comment": "Agent 0: Scout (temporal memory)"
            },
            {
              "type": "mha",
              "d_model": 32,
              "num_heads": 4,
              "seq_length": 1,
              "comment": "Agent 1: Analyzer (attention-based)"
            },
            {
              "type": "parallel",
              "combine_mode": "add",
              "branches": [
                {
                  "type": "dense",
                  "input_size": 32,
                  "output_size": 10,
                  "activation": "relu"
                },
                {
                  "type": "dense",
                  "input_size": 32,
                  "output_size": 10,
                  "activation": "gelu"
                },
                {
                  "type": "dense",
                  "input_size": 32,
                  "output_size": 10,
                  "activation": "tanh"
                }
              ],
              "comment": "Agent 2: Executor (ensemble decision)"
            },
            {
              "type": "rnn",
              "input_size": 32,
              "hidden_size": 10,
              "seq_length": 1,
              "comment": "Agent 3: Coordinator (sequential processing)"
            }
          ]
        }
      ]
    },
    "multi_scale": {
      "batch_size": 1,
      "grid_rows": 1,
      "grid_cols": 2,
      "layers_per_cell": 1,
      "layers": [
        {
          "type": "dense",
          "input_size": 24,
          "output_size": 24,
          "activation": "relu"
        },
        {
          "type": "parallel",
          "combine_mode": "grid_scatter",
          "grid_output_rows": 3,
          "grid_output_cols": 1,
          "grid_output_layers": 1,
          "grid_positions": [
            {
              "branch_index": 0,
              "target_row": 0,
              "target_col": 0,
              "target_layer": 0
            },
            {
              "branch_index": 1,
              "target_row": 1,
              "target_col": 0,
              "target_layer": 0
            },
            {
              "branch_index": 2,
              "target_row": 2,
              "target_col": 0,
              "target_layer": 0
            }
          ],
          "branches": [
            {
              "type": "layer_norm",
              "norm_size": 24,
              "epsilon": 1e-5,
              "comment": "Agent 0: LayerNorm processor"
            },
            {
              "type": "rms_norm",
              "norm_size": 24,
              "epsilon": 1e-5,
              "comment": "Agent 1: RMSNorm processor (Llama-style)"
            },
            {
              "type": "swiglu",
              "input_size": 24,
              "output_size": 24,
              "comment": "Agent 2: SwiGLU gated processor"
            }
          ]
        }
      ]
    }
  }
}